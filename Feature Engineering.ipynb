{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import pandas as pd\n",
    "\n",
    "#linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#regex\n",
    "import re\n",
    "\n",
    "#Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#online_coupon train data\n",
    "df_on=pd.read_csv(\"ccf_online_stage1_train.csv\")\n",
    "\n",
    "#offline_coupon train data\n",
    "df_off=pd.read_csv(\"ccf_offline_stage1_train.csv\")\n",
    "\n",
    "#offline_coupon test data\n",
    "df_off_test=pd.read_csv(\"ccf_offline_stage1_test_revised.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training dataset to fed to the model\n",
    "\n",
    "x = 'Null'\n",
    "df_off_unique = (df_off.fillna(x).groupby(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
    "       'Date_received', 'Date']).size().reset_index().rename(columns={0 : 'Count'}).replace(x,np.NaN))\n",
    "df_off_unique.drop(['Count'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "x = 'Null'    \n",
    "df_on_unique = (df_on.fillna(x).groupby(['User_id', 'Merchant_id', 'Action', 'Coupon_id', 'Discount_rate',\n",
    "                'Date_received', 'Date']).size().reset_index().rename(columns={0 : 'Count'}).replace(x,np.NaN))\n",
    "df_on_unique.drop(['Count'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_off_unique2=df_off_unique[df_off_unique['Date_received'].isna()==False].copy(deep=True)\n",
    "df_off_unique2['Date'] = pd.to_datetime(df_off_unique2['Date'],format=\"%Y%m%d\")\n",
    "df_off_unique2['Date_received'] = pd.to_datetime(df_off_unique2['Date_received'],format=\"%Y%m%d\")\n",
    "\n",
    "df_off_unique2[\"Redeem_date\"]=df_off_unique2[\"Date\"].dt.date-df_off_unique2[\"Date_received\"].dt.date\n",
    "df_off_unique2[\"Redeem_date\"]=df_off_unique2[\"Date\"].dt.date-df_off_unique2[\"Date_received\"].dt.date\n",
    "df_off_unique2['Redeem_date'] = df_off_unique2['Redeem_date'].dt.days.astype('str')\n",
    "df_off_unique2['Redeem_date'] = pd.to_numeric(df_off_unique2['Redeem_date'],errors=\"coerce\")\n",
    "split_data = df_off_unique2[\"Discount_rate\"].str.split(\":\")\n",
    "data = split_data.to_list()\n",
    "for i in range(len(data)):\n",
    "    if len(data[i])==1:\n",
    "        data[i].insert(1,100-float(data[i][0])*100)\n",
    "        data[i][0]=100\n",
    "        \n",
    "\n",
    "df_off_unique2['temp']=data\n",
    "df_off_unique2[['Original_Price','Discounted_price']] = pd.DataFrame(df_off_unique2.temp.values.tolist(), index= df_off_unique2.index)\n",
    "df_off_unique2[\"Original_Price\"]=df_off_unique2[\"Original_Price\"].astype(float)\n",
    "df_off_unique2[\"Discounted_price\"]=df_off_unique2[\"Discounted_price\"].astype(float)\n",
    "df_off_unique2[\"Rate\"]=round((df_off_unique2[\"Original_Price\"]-df_off_unique2[\"Discounted_price\"])/df_off_unique2[\"Original_Price\"],3)\n",
    "del df_off_unique2[\"temp\"] \n",
    "df_off_unique2[\"Redeem_date\"].fillna(-1, inplace = True) \n",
    "df_off_unique2[\"Distance\"].fillna(df_off_unique2[\"Distance\"].mean(), inplace = True) \n",
    "df_off_unique2[\"Target\"]=0\n",
    "df_off_unique2.loc[(df_off_unique2[\"Redeem_date\"]<=15) & (df_off_unique2[\"Redeem_date\"]>=0), 'Target'] = 1 \n",
    "df_off_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of coupons users received, redeemed and redemption rate\n",
    "def create_user_crr(df):\n",
    "    df2=df[df[\"Coupon_id\"].isna()==False]\n",
    "    df3=df2.groupby('User_id').agg({\"Coupon_id\":\"count\",\"Date\":\"count\"})\n",
    "    df3.rename(columns = {\"Coupon_id\": \"Coupon_receive_count\",\"Date\":\"Coupon_redeem_count\"}, inplace = True) \n",
    "    df3[\"User_Redeem_Receive_Ratio\"]=df3[\"Coupon_redeem_count\"]/df3[\"Coupon_receive_count\"]\n",
    "    df3.reset_index(inplace=True)\n",
    "    df3.sort_values(by=[\"Coupon_receive_count\"],ascending=False,inplace=True)\n",
    "    df=pd.merge(df,df3)\n",
    "    return df\n",
    "\n",
    "#avg distance of user from store\n",
    "def create_avg_dist_user(df):\n",
    "    df2=df_off_unique2.groupby('User_id').agg({\"Distance\":\"mean\"})\n",
    "    df2.rename(columns = {\"Distance\": \"User_avg_distance\"}, inplace = True) \n",
    "    df2.reset_index(inplace=True)\n",
    "    df=pd.merge(df,df2)\n",
    "    return df\n",
    "\n",
    "# no of different actions by users\n",
    "def create_no_of_actions(df_off_unique2,df_on_unique,df_off_unique):\n",
    "    list_on_off = set(df_on_unique[\"User_id\"].unique()).intersection(set(df_off_unique[\"User_id\"].unique()))\n",
    "    df_on_off = df_on[df_on['User_id'].isin(list(list_on_off))]\n",
    "    df=pd.get_dummies(df_on_off[\"Action\"])\n",
    "    df_on_off=pd.concat([df_on_off,df],axis=1)\n",
    "    df_on_off.rename(columns = {0: \"No_of_Clicks\",1:\"No_of_Buy\",2:\"No_of_Get_Coupons\"}, inplace = True) \n",
    "    df2=df_on_off.groupby('User_id').agg({\"No_of_Clicks\":\"count\",\"No_of_Buy\":\"count\",\"No_of_Get_Coupons\":\"count\"})\n",
    "    #df2[\"Buy_Click_Ratio\"]=df2[\"No_of_Buy\"]/df2[\"No_of_Clicks\"]\n",
    "    df2.reset_index(inplace=True)\n",
    "    df_off_unique2=pd.merge(df_off_unique2,df2)\n",
    "    return df_off_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off_unique2=create_user_crr(df_off_unique2)\n",
    "df_off_unique2=create_avg_dist_user(df_off_unique2)\n",
    "#df_off_unique2=create_no_of_actions(df_off_unique2,df_on_unique,df_off_unique)\n",
    "df_off_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off_unique2.to_csv(\"Train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
